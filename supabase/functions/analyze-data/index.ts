import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.39.3';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { question, fileId, sessionId, cardType } = await req.json();

    if (!question) {
      throw new Error('Question is required');
    }

    // Determine which card type to focus on
    const focusedType = cardType || 'all';

    const openAIApiKey = Deno.env.get('OPENAI_API_KEY');
    if (!openAIApiKey) {
      throw new Error('OpenAI API key not configured');
    }

    // Initialize Supabase client
    const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
    const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
    const supabase = createClient(supabaseUrl, supabaseKey);

    // Get file content if fileId is provided
    let fileContext = '';
    if (fileId) {
      const { data: fileData, error: fileError } = await supabase
        .from('uploaded_files')
        .select('file_path, file_name')
        .eq('id', fileId)
        .single();

      if (!fileError && fileData) {
        // Download file from storage
        const { data: fileContent, error: downloadError } = await supabase
          .storage
          .from('uploads')
          .download(fileData.file_path);

        if (!downloadError && fileContent) {
          const text = await fileContent.text();
          // Take first 10000 characters to avoid token limits
          fileContext = `\n\nDataset context (${fileData.file_name}):\n${text.substring(0, 10000)}`;
        }
      }
    }

    console.log('Calling OpenAI API with focus:', focusedType);

    // First, check database for predefined Q&A pairs
    const questionLower = question.toLowerCase();
    
    // Get user ID from auth header
    const authHeader = req.headers.get('authorization');
    let userId: string | null = null;
    
    if (authHeader) {
      try {
        const token = authHeader.replace('Bearer ', '');
        const { data: { user } } = await supabase.auth.getUser(token);
        userId = user?.id || null;
      } catch (e) {
        console.log('Could not extract user from token:', e);
      }
    }

    // Query database for matching Q&A pairs
    if (userId) {
      const { data: qaPairs, error: qaError } = await supabase
        .from('qa_pairs')
        .select('*')
        .eq('user_id', userId)
        .eq('is_active', true);

      if (!qaError && qaPairs && qaPairs.length > 0) {
        // Find best matching Q&A pair based on keywords
        const matchedQA = qaPairs.find(qa => {
          return qa.keywords.some((keyword: string) => 
            questionLower.includes(keyword.toLowerCase())
          );
        });

        if (matchedQA) {
          console.log('Found matching Q&A pair:', matchedQA.id);
          
          // For predefined Q&A, always return all three sections regardless of focusedType
          const result = {
            content: "Complete analysis from predefined Q&A",
            observation: matchedQA.observation_content || '',
            interpretation: matchedQA.interpretation_content || '',
            actionable_conclusion: matchedQA.actionable_content || ''
          };
          
          return new Response(JSON.stringify(result), {
            headers: { ...corsHeaders, 'Content-Type': 'application/json' },
          });
        }
      }
    }

    // Fallback to hardcoded Q&A pairs for brain tumor dataset (legacy)
    const isBrainTumorDataset = fileContext.includes('brain_tumor') || fileContext.includes('Tumor_Grade') || fileContext.includes('Glioblastoma');
    
    // Q1: Glioblastoma survival factors analysis
    if (isBrainTumorDataset && (
      questionLower.includes('glioblastoma') || 
      (questionLower.includes('survival') && questionLower.includes('factor'))
    )) {
      console.log('Matched Q1: Glioblastoma survival analysis');
      
      const completeAnalysis = `# ðŸ§¬ Glioblastoma Survival Analysis - Complete Report

---

## ðŸ“‹ 1. Analysis Plan

I'll analyze your brain tumor dataset to identify the key factors influencing patient survival. I'll start by loading the data, checking its quality, and then performing a comprehensive analysis focusing on tumor grade, biomarkers, and treatment types. I'll include a correlation matrix and statistical tests to determine significance.

---

## âœ… 2. Data Loading & Quality Check

**Status:** Data loaded successfully  
**Patient Records:** 300  
**Clinical Variables:** 12  
**Data Quality:** Excellent - no missing values in key columns

### ðŸ“Š Dataset Preview

| Patient_ID | Age | Gender | Tumor Size | Location | Grade | Status |
|:----------:|:---:|:------:|:----------:|:--------:|:-----:|:------:|
| 1 | 62 | M | 4.2 cmÂ³ | Frontal | III | âœ… Alive |
| 2 | 45 | F | 6.8 cmÂ³ | Temporal | IV | âŒ Deceased |
| 3 | 58 | M | 3.1 cmÂ³ | Parietal | II | âœ… Alive |

---

## ðŸ“ˆ 3. Initial Overview & Descriptive Statistics

First, let's understand our patient population. The distribution shows a **significant number of patients with high-grade tumors** (Grade III & IV), which aligns with the serious nature of glioblastoma.

> ðŸ“Š *Visual Reference: Bar chart â€“ Patient Distribution by Tumor Grade*

---

## ðŸ”— 4. Correlation Analysis

Now, examining the correlation matrix for numerical features. We can see **strong positive correlations** between Tumor_Grade and Tumor_Size, and **strong negative correlations** between both these factors and KPS_Score. 

This suggests that as tumors become more advanced and larger, patients' functional performance declines significantly.

### ðŸŽ¯ Key Correlation Insights

| Relationship | Correlation | Interpretation |
|:------------|:-----------:|:--------------|
| **Tumor Grade â†” Tumor Size** | **+0.82** | ðŸ”´ Strong Positive |
| **Tumor Grade â†” KPS Score** | **-0.76** | ðŸ”´ Strong Negative |
| **Biomarker 1 â†” Survival Time** | **-0.68** | ðŸŸ¡ Moderate Negative |

---

## ðŸ§ª 5. Statistical Testing & Group Comparisons

### Survival Analysis
To directly test survival relationships, I'm comparing tumor characteristics between survivors and non-survivors. The **Mann-Whitney U test** confirms that Tumor_Grade is significantly higher in deceased patients **(p < 0.001)**.

> ðŸ“Š *Visual Reference: Box plot â€“ Tumor Grade Distribution by Survival Status*

### Treatment Efficacy Analysis
Looking at treatment efficacy, patients receiving **Surgery+Radio show the highest survival rate at 78%**, compared to just 22% for Chemo alone. 

A **Chi-squared test** confirms this difference is statistically significant **(p < 0.001)**.

> ðŸ“Š *Visual Reference: Bar chart â€“ Survival Rates by Treatment Type*

---

## ðŸ§¬ 6. Biomarker Analysis

Your genomic biomarkers show **interesting patterns**:

- **Biomarker 1:** Strong negative correlation with survival time **(-0.68)**, suggesting it may be a **risk factor** ðŸ”´
- **Biomarker 2:** Positive correlation **(+0.54)**, potentially indicating a **protective effect** ðŸŸ¢

> ðŸ“Š *Visual Reference: Scatter plot â€“ Biomarker 1 Expression vs Survival Time*

---

# ðŸŽ¯ FINAL INSIGHT SUMMARY

## Key Factors Associated with Patient Survival

### 1ï¸âƒ£ **PRIMARY DRIVER: Tumor Grade** ðŸ”´
> **Impact:** This is the single strongest predictor  
> **Risk:** Grade IV patients have **8.3x higher mortality risk** than Grade I/II patients  
> **Significance:** p < 0.001

### 2ï¸âƒ£ **CRITICAL CO-FACTOR: Treatment Type** ðŸ’Š
> **Best Outcome:** Combination therapy (Surgery + Radio)  
> **Success Rate:** 78% survival rate vs. 22% for single-modality treatments  
> **Recommendation:** Multi-modal treatment approach strongly recommended

### 3ï¸âƒ£ **IMPORTANT PROGNOSTIC INDICATOR: KPS Performance Score** ðŸ“Š
> **Threshold:** Scores below 60 show dramatically worse outcomes  
> **Pattern:** Poor prognosis regardless of other factors  
> **Clinical Note:** Early functional status assessment is critical

### 4ï¸âƒ£ **PROMISING BIOMARKERS** ðŸ§¬
> **Biomarker 1 (Risk Factor):**  
> - High expression correlates with poor prognosis  
> - Potential therapeutic target for intervention  
> 
> **Biomarker 2 (Protective Factor):**  
> - High expression correlates with better outcomes  
> - May represent protective mechanism worth investigating

---

## ðŸ’¡ Clinical Implications

âœ… **Primary Focus:** Tumor grade remains the strongest predictor  
âœ… **Treatment Strategy:** Prioritize combination therapy approaches  
âœ… **Early Assessment:** Monitor KPS scores for prognostic insight  
âœ… **Research Direction:** Further investigate biomarker roles in treatment planning`;

      // Return complete analysis in observation field for single card display
      const result = {
        content: "Complete brain tumor survival analysis",
        observation: completeAnalysis,
        interpretation: '',
        actionable_conclusion: ''
      };
      
      return new Response(JSON.stringify(result), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }
    
    // Q2: Correlation and statistical analysis
    if (isBrainTumorDataset && (
      questionLower.includes('correlation') || 
      questionLower.includes('statistical') ||
      (questionLower.includes('relationship') && questionLower.includes('biomarker'))
    )) {
      console.log('Matched Q2: Statistical correlation analysis');
      
      const observationContent = `**What I showed/ran just now**

Head of the dataset and conversions; correlation matrix and heatmap; Wilcoxon/t-tests and Fisher/chi-squared by survival; logistic regression; then a reduced and Firth-corrected logistic model.

**Key reference outputs**

**Columns in the dataset I'm working with:**

[1] "Patient_ID"                     "Age"                           
[3] "Gender"                         "Tumor_Size_cm3"                
[5] "Tumor_Location"                 "Tumor_Grade"                   
[7] "Genomic_Biomarker_1_Expression" "Genomic_Biomarker_2_Expression"
[9] "Treatment_Type"                 "KPS_Performance_Score"         
[11] "Survival_Status"                "Survival_Time_Months"          
[13] "SurvBin"

**Survival status counts (Alive vs Deceased)** so we know the class balance.`;

      const interpretationContent = `**The initial reduced logistic model struggled to converge** (very small N + separation): 
Warning message: "glm.fit: algorithm did not converge"

**Summary of the reduced logistic glm** (note singularities due to separation/sparse cells):

Call:
glm(formula = SurvBin ~ Tumor_Size_cm3 + KPS_Performance_Score + 
    Genomic_Biomarker_1_Expression + Tumor_Grade + Treatment_Type, 
    family = binomial(), data = brain_df)

**Coefficients:** (2 not defined because of singularities)
                                 Estimate Std. Error z value Pr(>|z|)
(Intercept)                    -1.328e+01  1.684e+06       0        1
Tumor_Size_cm3                  2.188e-10  4.888e+04       0        1
KPS_Performance_Score          -1.080e-11  1.359e+04       0        1
Genomic_Biomarker_1_Expression -2.656e-09  9.348e+05       0        1
Tumor_Grade.L                   3.564e+01  2.361e+05       0        1
Tumor_Grade.Q                   2.657e+01  8.390e+04       0        1
Tumor_Grade.C                   1.188e+01  7.075e+04       0        1
Treatment_TypeRadio+Chemo      -1.823e-11  1.179e+05       0        1
Treatment_TypeSurgery                  NA         NA      NA       NA
Treatment_TypeSurgery+Radio            NA         NA      NA       NA

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 1.5388e+02  on 116  degrees of freedom
Residual deviance: 6.7879e-10  on 109  degrees of freedom
  (1 observation deleted due to missingness)
AIC: 16

**I installed logistf and its dependencies** to run a Firth logistic regression (handles separation better): also installing the dependencies 'ucminf', 'ordinal', 'pan', 'jomo', 'mitml', 'operator.tools', 'mice', 'formula.tools'`;

      const actionableContent = `**What this means (brief)**

- The dataset loads fine and has a reasonable mix of clinical, genomic, and survival variables.
- Logistic regression shows clear signs of quasi-complete separation and sparse categories for some factor levels (tiny sample with multiple predictors). That's why the standard glm didn't converge and why the Wald CIs explode.
- I switched to a Firth correction (logistf) to stabilize inference; those results are more trustworthy in this setting.

**If you want, I can:**

- Show the head again and a couple of quick plots (e.g., tumor size and KPS by survival).
- Print the full correlation heatmap and highlight any notable relationships.
- Summarize the Firth model outputs cleanly and visualize any significant predictors.`;

      // For hardcoded Q&A, always return all three sections regardless of focusedType
      const result = {
        content: "Complete statistical analysis of brain tumor dataset",
        observation: observationContent,
        interpretation: interpretationContent,
        actionable_conclusion: actionableContent
      };
      
      return new Response(JSON.stringify(result), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Create appropriate system prompt based on focus type
    let systemPrompt = '';
    if (focusedType === 'observation') {
      systemPrompt = `You are Neurika.ai, an AI Data Analyst. Analyze the dataset and provide a clear, factual OBSERVATION only.
Return JSON with: { "observation": "Clear factual summary of what the data shows, including specific numbers, trends, and patterns" }
Be thorough and specific in your observation.`;
    } else if (focusedType === 'interpretation') {
      systemPrompt = `You are Neurika.ai, an AI Data Analyst. Analyze the dataset and provide a deeper INTERPRETATION only.
Return JSON with: { "interpretation": "Deeper insights explaining WHY patterns exist, relationships between variables, and analytical conclusions" }
Focus on analytical depth and meaningful connections.`;
    } else if (focusedType === 'actionable') {
      systemPrompt = `You are Neurika.ai, an AI Data Analyst. Analyze the dataset and provide ACTIONABLE CONCLUSIONS only.
Return JSON with: { "actionable_conclusion": "Practical, strategic recommendations and specific actions to take based on the data" }
Be concrete and business-focused with your recommendations.`;
    } else {
      // Default: all three
      systemPrompt = `You are Neurika.ai, an AI Data Analyst. Analyze the given dataset and user question. 
Return your response as a JSON object with exactly these fields:
{
  "observation": "Clear, factual summary of what the data shows",
  "interpretation": "Deeper insights, patterns, or relationships detected",
  "actionable_conclusion": "Practical suggestions or conclusions from the data"
}
Focus on accuracy, insight, and clarity. Keep each section concise but informative.`;
    }

    // Call OpenAI API
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openAIApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: `Question: ${question}${fileContext}`
          }
        ],
        temperature: 0.7,
        max_tokens: focusedType === 'all' ? 1000 : 500,
        response_format: { type: "json_object" }
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('OpenAI API error:', response.status, errorText);
      throw new Error(`OpenAI API error: ${response.status}`);
    }

    const data = await response.json();
    console.log('OpenAI response received');

    const aiResponse = data.choices[0].message.content;
    
    // Try to parse JSON response
    let parsedResponse;
    try {
      parsedResponse = JSON.parse(aiResponse);
    } catch (e) {
      // If not valid JSON, create a structured response
      console.log('Response was not JSON, creating structured response');
      parsedResponse = {
        observation: aiResponse.substring(0, 300),
        interpretation: "See observation for details",
        actionable_conclusion: "Please refine your question for more specific insights"
      };
    }

    const result = {
      content: aiResponse,
      observation: parsedResponse.observation || '',
      interpretation: parsedResponse.interpretation || '',
      actionable_conclusion: parsedResponse.actionable_conclusion || '',
    };

    return new Response(JSON.stringify(result), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error) {
    console.error('Error in analyze-data function:', error);
    return new Response(
      JSON.stringify({ 
        error: error instanceof Error ? error.message : 'Unknown error',
        content: 'An error occurred while analyzing your data.',
        observation: 'Unable to process request',
        interpretation: 'Please try again',
        actionable_conclusion: 'Check your input and try again'
      }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  }
});